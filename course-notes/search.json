[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Visualization with R",
    "section": "",
    "text": "Abstract\nA reproducible research workflow should generate the same results from the same inputs every time. Unfortunately, software changes, key documentation is skipped, and that hard drive from graduate school disappeared during that last move. Reproducible research should be a minimum expectation of computational science, but too many researchers lack the tools to embrace a fully reproducible workflow. This full-day course aims to equip researchers with fundamental tools for reproducible research. The course will introduce Quarto, Git and GitHub, coding best practices, and environment management with renv through hands-on exercises and clear resources. Attendees will leave equipped to weather constantly changing software versions, documentation will be too fun to skip, and even a missing hard drive won’t ruin years of work. The course focuses on R but the content is broadly applicable.",
    "crumbs": [
      "Abstract"
    ]
  },
  {
    "objectID": "chapters/01_introduction-and-motivation.html",
    "href": "chapters/01_introduction-and-motivation.html",
    "title": "1  Introduction and Motivation",
    "section": "",
    "text": "2 Introductions\n\n2.0.1 Background\n\nLead Data Scientist for Statistical Computing at the Urban Institute\nAdjunct Professor in the McCourt School of Public Policy at Georgetown University\nAmerican Statistical Association Traveling Course Instructor\n\n\n\n2.0.2 R Projects\n\nSynthetic data generation (rstudio::conf(2022) talk about library(tidysynthesis))\nFormal privacy/differential privacy evaluation\n\nA Feasibility Study of Differentially Private Summary Statistics and Regression Analyses with Evaluations on Administrative and Survey Data (code) (JASA)\nBenchmarking DP Linear Regression Methods for Statistical Inference (Preprint)\n\nProjects that iterate with R Markdown/Quarto\n\nMobility Metrics data pages\nState Fiscal briefs\n\nManage the Urban Institute ggplot2 theme (Examples) (Code)\nUrban Institute R Users Group\n\n\n\n\n\n3 Outline\n\n3.0.1 Process\n\nPlease consider turning on your cameras.\nPlease ask questions at any time. You can speak up, raise your hand, or drop it in the chat.\nI need to know how you are doing. Please ask lots of questions and give your reactions.\nI will check in during breaks about pacing and content.\nWe will skip some exercises. Don’t worry, I’ve shared solutions to all exercises!\n\n\n\n3.0.2 Goals\n\nEnthusiasm\nDevelop a firm foundation with R\nLeave with enough understanding and resources that you can apply the covered material to your own work\n\nYou will still need to look stuff up!\nI will try to give you hints for where to find help\n\n\n\n\n\n\n4 Questions for You\n\nWhat types of analyses do you develop?\nWhat is your programming experience?\nWhat are you most interested to learn?\n\n\n\n\n5 Motivation\n\n5.0.1 Code-First Data Analysis\nI believe in a code-first approach to data analysis.\n\nCode maximizes the chance of catching mistakes when they inevitably happen.\nCode is the clearest way to document and share an analysis.\nReproducible code creates a single source of truth. Any result can be mapped back to the code and data that created the result.\nCode allows for robust version control.\nCode can scale analyses to bigger data and bigger projects.\nR code is entirely free and open source.\nCode is the best way to gain access to new techniques and cool stuff.\n\n\n\n\n\n6 Content\n\n6.0.1 Core Content\n\nIntroductions and Motivation\nGrammar of Graphics\nJon Schwabish’s Five Guidelines for Better Data Visualizations\n\n\n\n6.0.2 Optional Content\n\nVisualizing big data\nVisualizing regression models\nData munging for visualization\nVisualizing time series data\n\n\n\n\n\n7 Why Data Visualization?\n\nData visualization is exploratory data analysis (EDA)\nData visualization is diagnosis and validation\nData visualization is communication\n\n\n\n8 Why ggplot2\n\n8.0.1 1. Looks good!\nlibrary(ggplot2) is used by fivethirtyeight, Financial Times, BBC, the Urban Institute, and more.\n\n\n8.0.2 2. Flexible and expressive\nBy breaking data visualization into component parts, library(ggplot2) is a set of building blocks instead of a set of rigid cookie cutters.\n\n\n8.0.3 3. Reproducible\n\n\n\n\n\n\n\n\n\n\n\n8.0.4 4. Scalable\nIt’s almost as easy to make the 100th chart as it is to make the 2nd chart. This allows for iteration.\n\n\n8.0.5 5. In my analysis workflow\n\n\n\n\n\n\n\n\n\nData visualization is fundamental to EDA, statistical modeling, and basically any work with data. Too many people find themselves using different tools for data visualization and statistical modeling. R/ggplot2 allows everything to happen in the same script at the same time.\nToo often, switching from a programming language to Excel, results in parsing errors or cell-reference errors.\n\n\n\n\n9 R Markdown\n\nRStudio Tutorial\n\nThis short course will rely on R Markdown, which is a literate statistical programming framework that combines text and images, code, and code output into output documents like PDFs and web pages. It is like an easier-to-use LaTeX with more flexibility. Instead of .R scripts, we will use .Rmd scripts.\n\nMarkdown\nYAML Header\nCode chunks\n\n\n9.0.1 Running code in documents\nWe will mostly run code inside of .Rmd documents.\n\nRun the code like a .R script\nRun the entire current chunk \nRun all chunks above \n\n\n\n9.0.2 Knitting documents\nMore commonly, documents are knitted. This runs all of the code in the .Rmd in a new R session and then creates an output document like a .html or a .pdf. If the code has errors, knitting will fail.\nClick  when a .Rmd document is open in RStudio to knit the document.\n\n\n\n\n\n\nExercise 0\n\n\n\nStep 1: Open RStudio by double-clicking 2024_asa-data-viz.Rproj\nStep 2: Open 02_workbook.Rmd in RStudio. Make sure it is in 2024_asa-data-viz.Rproj. That is, you should not see Project: (None) in the top right of RStudio.\nStep 3: Click knit!",
    "crumbs": [
      "Core Content",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction and Motivation</span>"
    ]
  },
  {
    "objectID": "chapters/02_grammar-of-graphics.html",
    "href": "chapters/02_grammar-of-graphics.html",
    "title": "2  Grammar of Graphics",
    "section": "",
    "text": "3 The Tidy Approach",
    "crumbs": [
      "Core Content",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Grammar of Graphics</span>"
    ]
  },
  {
    "objectID": "chapters/02_grammar-of-graphics.html#resources",
    "href": "chapters/02_grammar-of-graphics.html#resources",
    "title": "2  Grammar of Graphics",
    "section": "5.1 Resources",
    "text": "5.1 Resources\n\nUrban Institute R Users Group website\nWhy the Urban Institute visualizes data with ggplot2\nR for Data Science: data visualization\nawunderground themes\nR Graph Gallery",
    "crumbs": [
      "Core Content",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Grammar of Graphics</span>"
    ]
  },
  {
    "objectID": "chapters/03_five-guidelines.html",
    "href": "chapters/03_five-guidelines.html",
    "title": "3  Jon Schwabish’s Five Guidelines in R",
    "section": "",
    "text": "3.1 Better Data Visualizations\nJon Schwabish wrote a book called Better Data Visualizations. Chapter two includes five guidelines for better data visualizations. We will work through the five guidelines with examples in library(ggplot2). Jon has taught me a ton about data viz and I taught Jon how to use R.",
    "crumbs": [
      "Core Content",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Jon Schwabish's Five Guidelines in R</span>"
    ]
  },
  {
    "objectID": "chapters/04_big-data.html",
    "href": "chapters/04_big-data.html",
    "title": "4  Visualizing Big Data",
    "section": "",
    "text": "5 Big Data\nOur examples thus far have focused on data sets with a modest number of observations and variables. Larger data sets can create new challenges.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Visualizing Big Data</span>"
    ]
  },
  {
    "objectID": "chapters/04_big-data.html#challenge-1-overplotting",
    "href": "chapters/04_big-data.html#challenge-1-overplotting",
    "title": "4  Visualizing Big Data",
    "section": "5.1 Challenge 1: Overplotting",
    "text": "5.1 Challenge 1: Overplotting\nOverplotting is when some geometric objects in a data visualization obscure other geometric objects. Overplotting is common when there is a highly frequent observation, if there is a lack of precision, or too many observations.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Visualizing Big Data</span>"
    ]
  },
  {
    "objectID": "chapters/04_big-data.html#challenge-2-too-many-pairwise-comparisons",
    "href": "chapters/04_big-data.html#challenge-2-too-many-pairwise-comparisons",
    "title": "4  Visualizing Big Data",
    "section": "5.2 Challenge 2: Too many pairwise comparisons",
    "text": "5.2 Challenge 2: Too many pairwise comparisons\nIf \\(m\\) is the number of variables in a data set, then there are \\(\\frac{m(m - 1)}{2}\\) pairwise relationships in a data set.\n\ntibble(m = 2:200) %&gt;%\n  mutate(`Pairwise Relationships` = m * (m - 1) / 2) %&gt;%\n  ggplot(aes(m, `Pairwise Relationships`)) +\n  geom_line() + \n  labs(\n    title = \"The Number of Pairwise Relationships Explodes in Modestly Wide Data\",\n    x = \"m (Number of predictors)\"\n  ) +\n  scale_y_continuous(labels = scales::comma)",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Visualizing Big Data</span>"
    ]
  },
  {
    "objectID": "chapters/05_linear-regression.html",
    "href": "chapters/05_linear-regression.html",
    "title": "5  Data Viz and Regression in R",
    "section": "",
    "text": "6 1. Create Models with ggplot2",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Viz and Regression in R</span>"
    ]
  },
  {
    "objectID": "chapters/05_linear-regression.html#geom_smooth",
    "href": "chapters/05_linear-regression.html#geom_smooth",
    "title": "5  Data Viz and Regression in R",
    "section": "6.1 geom_smooth()",
    "text": "6.1 geom_smooth()\nWe’ve already seen geom_smooth(), which adds a LOESS regression line with fewer than 1,000 observations and smoothing regression splines with 1,000 or more observations.\n\ncars %&gt;%\n  ggplot(mapping = aes(x = speed, y = dist)) +\n  geom_point() +\n  geom_smooth()\n\n\n\n\n\n\n\n\nWe can change the method to any of \"lm\", \"glm\", \"gam\", or \"loess\".\n\ncars %&gt;%\n  ggplot(mapping = aes(x = speed, y = dist)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\nWe can also change the formula and toggle off the standard error.\n\ncars %&gt;%\n  ggplot(mapping = aes(x = speed, y = dist)) +\n  geom_point() +\n  geom_smooth(\n    method = \"lm\", \n    formula = y ~ log(x), \n    se = FALSE\n  )\n\n\n\n\n\n\n\n\nThis final example is concise. It uses log(x) as a predictor but still shows the x axis in linear units.\ngeom_smooth() is useful for exploratory data analysis, but it is a little limiting. Next, we will consider developing models, cleaning the data, and making data visualizations as distinct steps.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Viz and Regression in R</span>"
    ]
  },
  {
    "objectID": "chapters/05_linear-regression.html#lm",
    "href": "chapters/05_linear-regression.html#lm",
    "title": "5  Data Viz and Regression in R",
    "section": "7.1 lm()",
    "text": "7.1 lm()\nlm() fits linear regression models in R. Here is a simple linear regression model estimated on the cars data with stopping distance as the dependent variable and speed as the independent variable.\n\nstopping_model &lt;- lm(formula = dist ~ speed, data = cars)\n\nclass(stopping_model)\n\n[1] \"lm\"\n\nstopping_model\n\n\nCall:\nlm(formula = dist ~ speed, data = cars)\n\nCoefficients:\n(Intercept)        speed  \n    -17.579        3.932  \n\n\nThe lm() function creates an object of class \"lm\". Many R functions have convenient (generic) methods for this object that are useful for understanding and using the output of a regression model.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Viz and Regression in R</span>"
    ]
  },
  {
    "objectID": "chapters/05_linear-regression.html#summary",
    "href": "chapters/05_linear-regression.html#summary",
    "title": "5  Data Viz and Regression in R",
    "section": "7.2 summary()",
    "text": "7.2 summary()\nsummary() returns a regression table with the call, a five number summary of the residuals, coefficient estimates, standard errors, t statistics, p-values, the residual standard error, \\(R^2\\), adjusted \\(R ^ 2\\), the F-statistic, and the p-value for the F-statistic.\n\nsummary(stopping_model)\n\n\nCall:\nlm(formula = dist ~ speed, data = cars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-29.069  -9.525  -2.272   9.215  43.201 \n\nCoefficients:\n            Estimate Std. Error t value         Pr(&gt;|t|)    \n(Intercept) -17.5791     6.7584  -2.601           0.0123 *  \nspeed         3.9324     0.4155   9.464 0.00000000000149 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15.38 on 48 degrees of freedom\nMultiple R-squared:  0.6511,    Adjusted R-squared:  0.6438 \nF-statistic: 89.57 on 1 and 48 DF,  p-value: 0.00000000000149",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Viz and Regression in R</span>"
    ]
  },
  {
    "objectID": "chapters/05_linear-regression.html#coef",
    "href": "chapters/05_linear-regression.html#coef",
    "title": "5  Data Viz and Regression in R",
    "section": "7.3 coef()",
    "text": "7.3 coef()\nFor example, coef() returns the coefficients.\n\ncoef(stopping_model)\n\n(Intercept)       speed \n -17.579095    3.932409",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Viz and Regression in R</span>"
    ]
  },
  {
    "objectID": "chapters/05_linear-regression.html#resid",
    "href": "chapters/05_linear-regression.html#resid",
    "title": "5  Data Viz and Regression in R",
    "section": "7.4 resid()",
    "text": "7.4 resid()\nresid() can be used to select just a vector of the residuals.\n\nresid(stopping_model)[1:10]\n\n        1         2         3         4         5         6         7         8 \n 3.849460 11.849460 -5.947766 12.052234  2.119825 -7.812584 -3.744993  4.255007 \n        9        10 \n12.255007 -8.677401",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Viz and Regression in R</span>"
    ]
  },
  {
    "objectID": "chapters/05_linear-regression.html#plot",
    "href": "chapters/05_linear-regression.html#plot",
    "title": "5  Data Viz and Regression in R",
    "section": "7.5 plot()",
    "text": "7.5 plot()\nplot() will return four plots with regression diagnostics.\n\n(1) Residual plot: This demonstrates if the residuals have non-linear patterns or non-constant variance.\n(2) Normal QQ plot: This demonstrates if the residuals are normally distributed.\n(3) Scale-Location plot: This also demonstrates if the residuals have non-constant variance.\n(4): Residuals vs. leverage plot This demonstrates cases that may be influential.\n\n\nplot(stopping_model)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot() with lm() is quick but the results are not attractive and customizing anything is a huge pain.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Viz and Regression in R</span>"
    ]
  },
  {
    "objectID": "chapters/05_linear-regression.html#librarybroom",
    "href": "chapters/05_linear-regression.html#librarybroom",
    "title": "5  Data Viz and Regression in R",
    "section": "8.1 library(broom)",
    "text": "8.1 library(broom)\nlibrary(broom) contains three helpful functions for tidying the output of estimated models. library(broom) is extensible and has methods for many models (lm(), glm(), kmeans(), LDA()). We will demonstrate applications with lm():\n\naugment() returns one row per observation in the estimation data and includes information like predicted values and residuals.\ntidy() returns one row per coefficient and includes information like point estimates and standard errors.\nglance() returns one row per model and includes information like \\(R^2\\).\n\n\n\n8.1.1 augment()\naugment() returns observation-level diagnostics like residuals and hat values.\n\naugment(stopping_model)\n\n# A tibble: 50 × 8\n    dist speed .fitted .resid   .hat .sigma  .cooksd .std.resid\n   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1     2     4   -1.85   3.85 0.115    15.5 0.00459       0.266\n 2    10     4   -1.85  11.8  0.115    15.4 0.0435        0.819\n 3     4     7    9.95  -5.95 0.0715   15.5 0.00620      -0.401\n 4    22     7    9.95  12.1  0.0715   15.4 0.0255        0.813\n 5    16     8   13.9    2.12 0.0600   15.5 0.000645      0.142\n 6    10     9   17.8   -7.81 0.0499   15.5 0.00713      -0.521\n 7    18    10   21.7   -3.74 0.0413   15.5 0.00133      -0.249\n 8    26    10   21.7    4.26 0.0413   15.5 0.00172       0.283\n 9    34    10   21.7   12.3  0.0413   15.4 0.0143        0.814\n10    17    11   25.7   -8.68 0.0341   15.5 0.00582      -0.574\n# ℹ 40 more rows\n\n\n\n\n8.1.2 Residual plot\nA residual plot compares fitted values and residuals. It is a useful diagnostic to see if there are non-linear patterns that are not captured by the model and to check for constant error variance.\n\n\n\n\n\n\nExercise 0\n\n\n\nLet’s estimate a model using a subset of the diamonds data set and then create a residual plot.\n\n# sample 300 observations and set ordinal factors to nominal\nset.seed(20200622)\n\ndiamonds &lt;- diamonds %&gt;%\n  slice_sample(n = 300) %&gt;%\n  mutate(across(where(is.factor), .fns = as.character))\n\n\n# estimate a multiple linear regression model\ndiamonds_model1 &lt;- lm(formula = price ~ carat + cut, data = diamonds)\n\nclass(diamonds_model1)\n\n[1] \"lm\"\n\n\nStep 1: Run the above code to estimate a linear regression model on a subset of the diamonds data.\nStep 2: Use augment() to create a data frame with one row per observation in the training data.\nStep 3: Create a scatter plot to compare .fitted and .resid. Add geom_smooth().\n\n\n\n\n\n8.1.3 tidy()\ntidy() returns coefficient-level diagnostics like standard errors and p-values.\n\ntidy(stopping_model)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   -17.6      6.76      -2.60 1.23e- 2\n2 speed           3.93     0.416      9.46 1.49e-12\n\n\n\n\n8.1.4 Coefficient plot\nHere’s a simple plot of estimated OLS coefficients and their 95% confidence intervals.\n\ndiamonds_model1_coefs &lt;- tidy(\n  diamonds_model1, \n  conf.int = TRUE,\n  conf.level = 0.95\n) \n\ndiamonds_model1_coefs %&gt;%\n  ggplot(aes(x = estimate, \n             y = term,\n             xmin = conf.low,\n             xmax = conf.high)) +\n  geom_vline(xintercept = 0) +\n  geom_pointrange() +\n  scale_x_continuous(\n    limits = c(-10000, 10000),\n    labels = scales::dollar\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 1\n\n\n\nLet’s estimate a second regression model on the diamonds data set and then compare the models with a coefficient plot.\nStep 1: Create diamonds_model2 with price as the dependent variable and carat, cut, and x as independent variables.\nStep 2: Use tidy() to create diamonds_model2_coefs. Combine the results using the following code:\n\nmodels_coefs &lt;- bind_rows(\n  `model1` = diamonds_model1_coefs,\n  `model2` = diamonds_model2_coefs,\n  .id = \"model\"\n)\n\nStep 3: Create a coefficient plot with models_coefs. Include color = model.\nStep 4: Add position = position_dodge(width = 0.5) to geom_pointrange().\n\n\n\nMichael Correll and Michael Gleicher have an interesting paper (preprint here) called “Error Bars Considered Harmful: Exploring Alternate Encodings for Mean and Error”. Consider this figure from their paper:\n\n\n\n\n\n\n\n\n\nHere, (a) suffers from within the bar bias, and (a) and (b) suffers from issues with binary interpretation. It’s tricky to fully adopt (c) or (d), which are visually symmetric and visually continuous, but I never use bars for coefficients and I never use the “capital I” error bars.\n\n\n\n8.1.5 glance()\nglance() returns model-level diagnostics like \\(R^2\\) and \\(\\hat{\\sigma}\\).\n\nglance(stopping_model)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.651         0.644  15.4      89.6 1.49e-12     1  -207.  419.  425.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\nIt isn’t interesting to visualize one model using glance(). However, glance() allows for the comparison of many models.\n\n\n8.1.6 Detailed Example: Creating Many models\nHadley Wickham gave a great talk about estimating many models to the The Edinburgh R User Group. (The relevant sections begins around the 28-minute mark). Here is an example based on his talk:\n\nlibrary(gapminder)\n\nglimpse(gapminder)\n\nRows: 1,704\nColumns: 6\n$ country   &lt;fct&gt; \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", …\n$ continent &lt;fct&gt; Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, …\n$ year      &lt;int&gt; 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, …\n$ lifeExp   &lt;dbl&gt; 28.801, 30.332, 31.997, 34.020, 36.088, 38.438, 39.854, 40.8…\n$ pop       &lt;int&gt; 8425333, 9240934, 10267083, 11537966, 13079460, 14880372, 12…\n$ gdpPercap &lt;dbl&gt; 779.4453, 820.8530, 853.1007, 836.1971, 739.9811, 786.1134, …\n\n\nThe gapminder data set contains information about life expectancy, population, and per-capita GDP over time for every country in the world. It comes from Hans Rosling and the Gapminder Foundation.\nWe can estimate a simple linear regression for every country in the data set with year as the predictor and lifeExp as the outcome variable.\n\n# estimate a linear model for each country\nmany_models &lt;- gapminder %&gt;%\n  group_by(country, continent) %&gt;%\n  # create a nested data frame for each county\n  nest(data = c(year, lifeExp, pop, gdpPercap)) %&gt;%\n  # iterate down each row and estimate a model with the nested data frame\n  mutate(\n    model = map(\n      .x = data, \n      .f = ~glance(lm(formula = lifeExp ~ year, data = .x))\n    )\n  ) %&gt;%\n  ungroup()\n    \n# extract r^2 from each model\nmany_models_results &lt;- many_models %&gt;%\n  mutate(r_squared = map_dbl(model, \"r.squared\"))\n\n# plot\nmany_models_results %&gt;%\n  # reorder the data based on r_squared\n  mutate(country = forcats::fct_reorder(.f = country, .x = r_squared)) %&gt;%\n  ggplot(mapping = aes(r_squared, country, color = continent)) +\n  geom_point(alpha = 0.5)\n\n\n\n\n\n\n\n\nmap() functions come from library(purrr) and are based on the Map-Reduce framework. This is a functional approach to iteration that replaces for loops. I recommend reading more here.\nCategorical variables are displayed in alphanumeric order by default. fct_reorder() from library(forcats) converts country to a factor and orders it based on the values of r_squared. library(forcats)has several useful functions for ordering categorical axes with library(ggplot2).\nLet’s clean this up a little:\n\nbind_rows(\n  `High R-Squared` = slice_max(many_models_results, r_squared, n = 15),\n  `Low R-Squared` = slice_min(many_models_results, r_squared, n = 15),\n  .id = \"R-Squared\"\n) %&gt;%\n  mutate(country = forcats::fct_reorder(.f = country, .x = r_squared)) %&gt;%\n  ggplot(mapping = aes(r_squared, country, color = continent)) +\n  geom_point(alpha = 0.5) +\n  facet_wrap(~ `R-Squared`, nrow = 2, scales = \"free_y\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\nStep 1: Like above, estimate many models on the diamonds data set. Group by color. You will need to list columns in the nest() functions. Use formula = price ~ carat + cut.\nStep 2: Extract \\(R^2\\) from each model.\nStep 3: Visualize the \\(R^2\\) with a scatter plot with r_squared on the x axis and color on the y axis.\nStep 4: Add scale_x_continuous(limits = c(0, 1)).",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Viz and Regression in R</span>"
    ]
  },
  {
    "objectID": "chapters/05_linear-regression.html#add_predictions",
    "href": "chapters/05_linear-regression.html#add_predictions",
    "title": "5  Data Viz and Regression in R",
    "section": "9.1 add_predictions()",
    "text": "9.1 add_predictions()\nadd_predictions() adds predictions to a data set using an estimated model object.\n\nadd_predictions(data = diamonds, model = diamonds_model1)\n\n# A tibble: 300 × 11\n   carat cut       color clarity depth table price     x     y     z   pred\n   &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1  0.7  Very Good I     VVS1     62.9    58  2513  5.65  5.67  3.56  3070.\n 2  1.52 Ideal     I     SI2      61.7    57  7582  7.38  7.41  4.56 10154.\n 3  0.31 Ideal     H     SI1      61.3    55   421  4.35  4.39  2.68   198.\n 4  0.71 Ideal     D     VS2      59.9    57  3540  5.8   5.83  3.48  3489.\n 5  2.07 Ideal     I     SI2      62      55 16189  8.12  8.22  5.07 14680.\n 6  1    Ideal     E     SI2      61.9    56  4760  6.43  6.4   3.97  5876.\n 7  1.2  Ideal     G     SI1      61.2    56  7920  6.87  6.88  4.21  7521.\n 8  0.52 Good      H     VS2      63.7    54  1385  5.12  5.09  3.25  1409.\n 9  0.65 Very Good G     VS2      63.2    57  2009  5.54  5.47  3.48  2659.\n10  0.49 Premium   F     SI2      62.2    59  1073  5.09  5.04  3.15  1392.\n# ℹ 290 more rows",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Viz and Regression in R</span>"
    ]
  },
  {
    "objectID": "chapters/05_linear-regression.html#add_residuals",
    "href": "chapters/05_linear-regression.html#add_residuals",
    "title": "5  Data Viz and Regression in R",
    "section": "9.2 add_residuals()",
    "text": "9.2 add_residuals()\nadd_residuals() adds residuals to a data set using an estimated model object.\n\nadd_residuals(data = diamonds, model = diamonds_model1)\n\n# A tibble: 300 × 11\n   carat cut       color clarity depth table price     x     y     z   resid\n   &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1  0.7  Very Good I     VVS1     62.9    58  2513  5.65  5.67  3.56  -557. \n 2  1.52 Ideal     I     SI2      61.7    57  7582  7.38  7.41  4.56 -2572. \n 3  0.31 Ideal     H     SI1      61.3    55   421  4.35  4.39  2.68   223. \n 4  0.71 Ideal     D     VS2      59.9    57  3540  5.8   5.83  3.48    50.6\n 5  2.07 Ideal     I     SI2      62      55 16189  8.12  8.22  5.07  1509. \n 6  1    Ideal     E     SI2      61.9    56  4760  6.43  6.4   3.97 -1116. \n 7  1.2  Ideal     G     SI1      61.2    56  7920  6.87  6.88  4.21   399. \n 8  0.52 Good      H     VS2      63.7    54  1385  5.12  5.09  3.25   -23.9\n 9  0.65 Very Good G     VS2      63.2    57  2009  5.54  5.47  3.48  -650. \n10  0.49 Premium   F     SI2      62.2    59  1073  5.09  5.04  3.15  -319. \n# ℹ 290 more rows",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Viz and Regression in R</span>"
    ]
  },
  {
    "objectID": "chapters/05_linear-regression.html#data_grid",
    "href": "chapters/05_linear-regression.html#data_grid",
    "title": "5  Data Viz and Regression in R",
    "section": "9.3 data_grid()",
    "text": "9.3 data_grid()\ndata_grid() creates an evenly-spaced grid of points using the range of observed predictors in a data set. This is useful for visualization and is really, really useful for understanding generalized linear models. seq_range() can be used with data_grid() to add a finer grid of values.\n\ndata_grid(data = diamonds, carat, cut) %&gt;%\n  add_predictions(diamonds_model1)\n\n# A tibble: 465 × 3\n   carat cut         pred\n   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1  0.2  Fair      -2010.\n 2  0.2  Good      -1224.\n 3  0.2  Ideal      -707.\n 4  0.2  Premium    -995.\n 5  0.2  Very Good -1044.\n 6  0.23 Fair      -1763.\n 7  0.23 Good       -977.\n 8  0.23 Ideal      -460.\n 9  0.23 Premium    -748.\n10  0.23 Very Good  -797.\n# ℹ 455 more rows\n\n\n\ncut_levels &lt;- c(\"Fair\", \"Good\",  \"Very Good\", \"Ideal\", \"Premium\")\n\ndata_grid(data = diamonds, carat, cut) %&gt;%\n  add_predictions(diamonds_model1) %&gt;%\n  mutate(cut = factor(cut, levels = cut_levels)) %&gt;%\n  ggplot(aes(x = carat, y = pred, color = cut)) +\n  geom_line(alpha = 0.5) +\n  scale_x_continuous(\n    limits = c(0, 3),\n    expand = c(0, 0)\n  ) +\n  scale_y_continuous(\n    limits = c(-5000, 20000),\n    expand = c(0, 0),\n    labels = scales::dollar\n  ) +\n  labs(title = \"data_grid() is useful for interpreting a regression line\")\n\n\n\n\n\n\n\n\nCategorical variables are displayed in alphanumeric order by default. Here, we use factor() to give cut a meaningful order: “Fair”, “Good”, “Very Good”, “Ideal”, and “Premium”.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Viz and Regression in R</span>"
    ]
  },
  {
    "objectID": "chapters/05_linear-regression.html#complex-models-and-glms",
    "href": "chapters/05_linear-regression.html#complex-models-and-glms",
    "title": "5  Data Viz and Regression in R",
    "section": "9.4 Complex Models and GLMs",
    "text": "9.4 Complex Models and GLMs\nlibrary(modelr) is useful for visualizing complex models such as polynomial regression or generalized linear models (GLMs) like logistic regression.\n\nset.seed(20201005)\n\n# simulate a predictor\nx1 &lt;- runif(n = 1000, min = 0, max = 10)\n\n# simulate the outcome and create a tibble\nsim_data &lt;- bind_cols(\n  x1 = x1,\n  y = 10 * sin(x1) + 20 + rnorm(n = length(x1), mean = 0, sd = 2)\n)\n\n# plot\nsim_data %&gt;%\n  ggplot(aes(x1, y)) +\n  geom_point(alpha = 0.1)\n\n\n\n\n\n\n\n\nLet’s fit a 4th-degree polynomial and then add a line for the conditional mean. We could also use augment() in this case because the x1 is dense. If there are gaps in predictors, then data_grid() is necessary.\n\n# fit a model with a 4th-degree polynomial\nlm_4 &lt;- sim_data %&gt;%\n  lm(formula = y ~ poly(x1, degrees = 4, raw = TRUE), data = .)\n\n# create a grid andd predictions\nconditional_mean &lt;- data_grid(sim_data, x1) %&gt;%\n  add_predictions(lm_4)\n\n# plot\nggplot() +\n  geom_point(\n    data = sim_data,\n    mapping = aes(x1, y),\n    alpha = 0.1\n  ) +\n  geom_line(\n    data = conditional_mean,\n    mapping = aes(x1, pred),\n    color = \"red\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 3\n\n\n\nThis example will demonstrate plotting predicted probabilities for a simple logistic regression model.\nStep 1: Run the following to create a binary outcome variable.\ncars &lt;- cars %&gt;%\n  mutate(crash = as.numeric(dist &gt; 25))\n\nStep 2: Using lm(), estimate a linear regression model (linear probability model) with crash as the outcome variable and speed as the predictor. Call it cars_lm.\nStep 3: Run the following to estimate a logistic regression model:\ncars_glm &lt;- glm(factor(crash) ~ speed, data = cars, family = \"binomial\")\n\nStep 4: Use data_grid() to create a new data frame. Use speed = seq_range(speed, 1000) to make a consistent grid of values for speed.\nStep 5: Create a data frame with conditional probabilities for both models with the following code:\nmodels &lt;- data_grid(cars, speed = seq_range(speed, 1000)) %&gt;%\n  add_predictions(cars_lm, var = \"lm\") %&gt;%\n  add_predictions(cars_glm, type = \"response\", var = \"glm\")\nStep 6: Plot the predicted probabilities for the linear probability model and logistic regression model. I used three layers: geom_point(), geom_line() with y = lm, and geom_line() with y = glm.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Viz and Regression in R</span>"
    ]
  },
  {
    "objectID": "chapters/06_data-munging.html",
    "href": "chapters/06_data-munging.html",
    "title": "6  Data Munging for Data Visualization",
    "section": "",
    "text": "6.1 Import Packages and Functions",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Munging for Data Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/06_data-munging.html#import-packages-and-functions",
    "href": "chapters/06_data-munging.html#import-packages-and-functions",
    "title": "6  Data Munging for Data Visualization",
    "section": "",
    "text": "filter() - drop cases based on logical conditions\nmutate() - add new variables are transform existing variables\npivot_wider() - make data wider\npivot_longer() - make data longer\nseparate() - split a character variable into multiple columns based on a delimiter",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Munging for Data Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/06_data-munging.html#tidy-data",
    "href": "chapters/06_data-munging.html#tidy-data",
    "title": "6  Data Munging for Data Visualization",
    "section": "6.2 Tidy Data",
    "text": "6.2 Tidy Data\nThis data comes from library(tidyr) and these examples largely come from chapter 12 in R for Data Science by Hadley Wickham and Garrett Grolemund.\n\ntable1, table2, table3, table4a, table4b, and table5 all display the number of TB cases documented by the World Health Organization in Afghanistan, Brazil, and China between 1999 and 2000.\n\nThe following table, table1 is tidy because\n\nEach variable has its own column\nEach observation has its own row\nEach value has its own cell\n\n\ntable1\n\n# A tibble: 6 × 4\n  country      year  cases population\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Munging for Data Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/06_data-munging.html#untidy-table2",
    "href": "chapters/06_data-munging.html#untidy-table2",
    "title": "6  Data Munging for Data Visualization",
    "section": "6.3 Untidy table2",
    "text": "6.3 Untidy table2\n\n6.3.1 Untidy\nWhy aren’t the data tidy?\n\ntable2\n\n# A tibble: 12 × 4\n   country      year type            count\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;\n 1 Afghanistan  1999 cases             745\n 2 Afghanistan  1999 population   19987071\n 3 Afghanistan  2000 cases            2666\n 4 Afghanistan  2000 population   20595360\n 5 Brazil       1999 cases           37737\n 6 Brazil       1999 population  172006362\n 7 Brazil       2000 cases           80488\n 8 Brazil       2000 population  174504898\n 9 China        1999 cases          212258\n10 China        1999 population 1272915272\n11 China        2000 cases          213766\n12 China        2000 population 1280428583\n\n\n\n\n6.3.2 Cleaned\nEach observation was spread across two rows!\n\ntable2 %&gt;%\n  pivot_wider(names_from = type, values_from = count)\n\n# A tibble: 6 × 4\n  country      year  cases population\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Munging for Data Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/06_data-munging.html#untidy-table3",
    "href": "chapters/06_data-munging.html#untidy-table3",
    "title": "6  Data Munging for Data Visualization",
    "section": "6.4 Untidy table3",
    "text": "6.4 Untidy table3\n\n6.4.1 Untidy\nWhy aren’t the data tidy?\n\ntable3\n\n# A tibble: 6 × 3\n  country      year rate             \n  &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;            \n1 Afghanistan  1999 745/19987071     \n2 Afghanistan  2000 2666/20595360    \n3 Brazil       1999 37737/172006362  \n4 Brazil       2000 80488/174504898  \n5 China        1999 212258/1272915272\n6 China        2000 213766/1280428583\n\n\n\n\n6.4.2 Cleaned\nThe rate column had two variables!\n\ntable3 %&gt;%\n  separate(rate, into = c(\"cases\", \"population\")) %&gt;%\n  mutate(\n    cases = as.numeric(cases),\n    population = as.numeric(population)\n  )\n\n# A tibble: 6 × 4\n  country      year  cases population\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Munging for Data Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/06_data-munging.html#untidy-table4",
    "href": "chapters/06_data-munging.html#untidy-table4",
    "title": "6  Data Munging for Data Visualization",
    "section": "6.5 Untidy table4",
    "text": "6.5 Untidy table4\n\n6.5.1 Untidy\nWhy aren’t the data tidy?\n\ntable4a\n\n# A tibble: 3 × 3\n  country     `1999` `2000`\n  &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n1 Afghanistan    745   2666\n2 Brazil       37737  80488\n3 China       212258 213766\n\ntable4b\n\n# A tibble: 3 × 3\n  country         `1999`     `2000`\n  &lt;chr&gt;            &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan   19987071   20595360\n2 Brazil       172006362  174504898\n3 China       1272915272 1280428583\n\n\n\n\n6.5.2 Cleaned\nEach table had variables in the column names and the data were spread across two tables\n\n# fix table4a\ntable4a_fixed &lt;- table4a %&gt;%\n  pivot_longer(\n    cols = c(`1999`, `2000`), \n    names_to = \"year\", \n    values_to = \"cases\"\n  )\n\n# fix table4b\ntable4b_fixed &lt;- table4b %&gt;%\n  pivot_longer(\n    cols = c(`1999`, `2000`), \n    names_to = \"year\", \n    values_to = \"population\"\n  )\n\n# join the two tables into one tidy table\nleft_join(\n  table4a_fixed, \n  table4b_fixed, \n  by = c(\"country\", \"year\")\n)\n\n# A tibble: 6 × 4\n  country     year   cases population\n  &lt;chr&gt;       &lt;chr&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan 1999     745   19987071\n2 Afghanistan 2000    2666   20595360\n3 Brazil      1999   37737  172006362\n4 Brazil      2000   80488  174504898\n5 China       1999  212258 1272915272\n6 China       2000  213766 1280428583",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Munging for Data Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/06_data-munging.html#titanic-data",
    "href": "chapters/06_data-munging.html#titanic-data",
    "title": "6  Data Munging for Data Visualization",
    "section": "6.6 Titanic Data",
    "text": "6.6 Titanic Data\nConsider the Titanic data set from the 3D plots example.\n\ntribble(\n  ~Class, ~Sex, ~n,\n  \"1st class\", \"female passengers\", 144,\n  \"1st class\", \"male passengers\", 179,\n  \"2nd class\", \"female passengers\", 106,\n  \"2nd class\", \"male passengers\", 171, \n  \"3rd class\", \"female passengers\", 216,\n  \"3rd class\", \"male passengers\", 493\n)\n\n\n\n\n\n\n\nExercise 0\n\n\n\nTidy the following data:\n\ntribble(\n  ~Class, ~female_passengers, ~male_passengers,\n  \"1st class\", 144, 179,\n  \"2nd class\", 106, 171,\n  \"3rd class\", 216, 493\n)\n\n\n\n\n\n\n\n\n\nExercise 1\n\n\n\nTidy the following data:\n\ntribble(\n  ~Class, ~`male passengers/female passengers`,\n  \"1st class\", \"179|144\",\n  \"2nd class\", \"171|106\",\n  \"3rd class\", \"493|216\",\n)\n\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\nSuppose we want to create a column chart with only female passengers. Furthermore, we want n on the x-axis and we want Class on the y-axis with the levels going from 1st to 3rd from top to bottom.\nStep 1: Use filter() to drop male passengers.\nStep 2: Create a column chart with n on the x-axis and Class on the y-axis. Pipe (%&gt;%) the data into ggplot().\nStep 3: After the filter(), add the following:\n  mutate(Class = factor(Class, levels = c(\"3rd class\", \"2nd class\", \"1st class\"))) %&gt;%",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Munging for Data Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/06_data-munging.html#additional-tools",
    "href": "chapters/06_data-munging.html#additional-tools",
    "title": "6  Data Munging for Data Visualization",
    "section": "6.7 Additional tools",
    "text": "6.7 Additional tools\n\nlibrary(stringr) has powerful tools for dealing with text strings.\nlibrary(lubridate) has powerful tools for dealing with time and dates.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data Munging for Data Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/07_time-series.html",
    "href": "chapters/07_time-series.html",
    "title": "7  Time Series and Annotations in R",
    "section": "",
    "text": "8 Introduction\nThis guide is an introduction to visualizing time series data in R and improving data visualization annotations. In this case, time series just means long data with a date variable or date-time variable. R has a native time series object and a “tidy” tsibble object. This training will not address those types of data.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Time Series and Annotations in R</span>"
    ]
  },
  {
    "objectID": "chapters/07_time-series.html#dates",
    "href": "chapters/07_time-series.html#dates",
    "title": "7  Time Series and Annotations in R",
    "section": "9.1 Dates",
    "text": "9.1 Dates\nThere are many ways to store dates.\n\nMarch 14, 1992\n03/14/1992\n14/03/1992\n14th of March ’92\n\nOne way of storing dates is the best. The ISO 8601 date format is an international standard with appealing properties like fixed lengths and self ordering. The format is YYYY-MM-DD.\nlibrary(lubridate) has useful functions that will take dates of any format and convert them to the ISO 8601 standard.\n\nlibrary(lubridate)\n\nmdy(\"March 14, 1992\")\n\n[1] \"1992-03-14\"\n\nmdy(\"03/14/1992\")\n\n[1] \"1992-03-14\"\n\ndmy(\"14/03/1992\")\n\n[1] \"1992-03-14\"\n\ndmy(\"14th of March '92\")\n\n[1] \"1992-03-14\"\n\n\nThese functions return variables of class \"Date\".\n\nclass(mdy(\"March 14, 1992\"))\n\n[1] \"Date\"",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Time Series and Annotations in R</span>"
    ]
  },
  {
    "objectID": "chapters/07_time-series.html#date-times",
    "href": "chapters/07_time-series.html#date-times",
    "title": "7  Time Series and Annotations in R",
    "section": "9.2 Date Times",
    "text": "9.2 Date Times\nlibrary(lubridate) also contains functions for parsing date times into ISO 8601 standard. Times are slightly trickier because of time zones.\n\nmdy_hms(\"12/02/2021 1:00:00\")\n\n[1] \"2021-12-02 01:00:00 UTC\"\n\nmdy_hms(\"12/02/2021 1:00:00\", tz = \"EST\")\n\n[1] \"2021-12-02 01:00:00 EST\"\n\nmdy_hms(\"12/02/2021 1:00:00\", tz = \"America/Chicago\")\n\n[1] \"2021-12-02 01:00:00 CST\"\n\n\nBy default, library(lubridate) will put the date times in Coordinated Universal Time (UTC), which is the successor to Greenwich Mean Time (GMT). I recommend carefully reading the data dictionary if time zones are important for your analysis or if your data cross time zones. This is especially important during time changes (e.g. “spring forward” and “fall back”).\nFortunately, if you encode your dates or date-times correctly, then library(lubridate) will automatically account for time changes, time zones, leap years, leap seconds, and all of the quirks of dates and times.\n\n\n\n\n\n\n\nExercise 0\n\n\n\n\ndates &lt;- tribble(\n  ~date,\n  \"12/01/1987\",\n  \"12/02/1987\",\n  \"12/03/1987\"\n)\n\nStep 1: Create the dates data from above with tribble().\nStep 2: Use mutate() to convert the date column to the ISO 8601 standard.",
    "crumbs": [
      "Special Topics",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Time Series and Annotations in R</span>"
    ]
  },
  {
    "objectID": "chapters/08_where-to-go-from-here.html",
    "href": "chapters/08_where-to-go-from-here.html",
    "title": "8  Where to Go From Here!",
    "section": "",
    "text": "8.1 Publications",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Where to Go From Here!</span>"
    ]
  },
  {
    "objectID": "chapters/08_where-to-go-from-here.html#publications",
    "href": "chapters/08_where-to-go-from-here.html#publications",
    "title": "8  Where to Go From Here!",
    "section": "",
    "text": "R for Data Science by Hadley Wickham and Garrett Grolemund\nggplot2: elegant graphics for data analysis by Hadley Wickham, Danielle Navarro, and Thomas Lin Pedersen\nFundamentals of Data Visualization by Claus O. Wilke\nBetter Data Visualizations: A Guide for Scholars, Researchers, and Wonks by Jon Schwabish\nR Markdown: The Definitive Guide by Yihui Xie, J. J. Allaire, Garrett Grolemund\nfivethirtyeight best and weirdest charts",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Where to Go From Here!</span>"
    ]
  },
  {
    "objectID": "chapters/08_where-to-go-from-here.html#people-and-places",
    "href": "chapters/08_where-to-go-from-here.html#people-and-places",
    "title": "8  Where to Go From Here!",
    "section": "8.2 People and Places",
    "text": "8.2 People and Places\n\nYihui Xie\nMona Chalabi\nData@Urban\nRStudio education",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Where to Go From Here!</span>"
    ]
  },
  {
    "objectID": "chapters/08_where-to-go-from-here.html#tidy-tuesday",
    "href": "chapters/08_where-to-go-from-here.html#tidy-tuesday",
    "title": "8  Where to Go From Here!",
    "section": "8.3 Tidy Tuesday",
    "text": "8.3 Tidy Tuesday\nGitHub\nCheck out #TidyTuesday on Twitter to follow the submissions\n\nA weekly data project aimed at the R ecosystem. As this project was borne out of the R4DS Online Learning Community and the R for Data Science textbook, an emphasis was placed on understanding how to summarize and arrange data to make meaningful charts with ggplot2, tidyr, dplyr, and other tools in the tidyverse ecosystem. However, any code-based methodology is welcome - just please remember to share the code used to generate the results.\n\nDavid Robinson, a great data analyst and R package developer, often records live videos where he talks his way through a #TidyTuesday event.",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Where to Go From Here!</span>"
    ]
  },
  {
    "objectID": "chapters/08_where-to-go-from-here.html#getting-help",
    "href": "chapters/08_where-to-go-from-here.html#getting-help",
    "title": "8  Where to Go From Here!",
    "section": "8.4 Getting help",
    "text": "8.4 Getting help\n\n8.4.1 Googling\nWhen Googling for R or data science help, set the search range to the last year or less to avoid out-of-date solutions and to focus on up-to-date practices. The search window can be set by clicking Tools after a Google search.\n\n\n8.4.2 Stack Overflow\nStack Overflow contains numerous solutions. If a problem is particularly perplexing, it is simple to submit questions. Exercise caution when submitting questions because the Stack Overflow community has strict norms about questions and loose norms about respecting novices.\n\n\n8.4.3 RStudio community\nRStudio Community is a new forum for R Users. It has a smaller back catalog than Stack Overflow but users are friendlier than on Stack Overflow.\n\n\n8.4.4 CRAN task views\nCRAN task views contains thorough introductions to packages and techniques organized by subject matter. The Econometrics, Reproducible Research, and and Social Sciences task views are good starting places.\n\n\n8.4.5 Twitter\nTwitter is mostly bad. But the #rstats hashtag and #rstats community are mostly good. They are also generally inclusive and civil. In particular, open sources developers like Hadley Wickham (@hadleywickham) and Jenny Bryan (@JennyBryan) are active.\nI am somewhat happy on Twitter at @awunderground and I am always willing to help with issues.",
    "crumbs": [
      "Additional Resources",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Where to Go From Here!</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible-research-bootcamp_software-installation.html",
    "href": "chapters/reproducible-research-bootcamp_software-installation.html",
    "title": "Appendix A — Software Requirements",
    "section": "",
    "text": "B Installing R and RStudio\nR is an open source statistical programming language. RStudio is an Integrated Development Environment (IDE) for developing R code. RStudio is developed by the for-profit company Posit. Don’t worry, you don’t need to pay any money for this software.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Software Requirements</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible-research-bootcamp_software-installation.html#windows",
    "href": "chapters/reproducible-research-bootcamp_software-installation.html#windows",
    "title": "Appendix A — Software Requirements",
    "section": "B.1 Windows",
    "text": "B.1 Windows\n\nB.1.1 R\n\nNavigate to the CRAN website.\nClick “Download R for Windows”\nClick “base”\nClick “Download R 4.4.1 for Windows”\nFollow the installation instructions. Accept all defaults and install R.\n\n\n\nB.1.2 RStudio\n\nNavigate to the RStudio website.\nDownload the RStudio Desktop installer for Windows. It should be something similar to “RStudio-2024.04.2-764.exe”.\nFollow the installation instructions. Accept all defaults and install RStudio.\nOpen RStudio. If successful, then R and RStudio are installed.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Software Requirements</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible-research-bootcamp_software-installation.html#mac",
    "href": "chapters/reproducible-research-bootcamp_software-installation.html#mac",
    "title": "Appendix A — Software Requirements",
    "section": "B.2 Mac",
    "text": "B.2 Mac\n\nB.2.1 R\n\nNavigate to the CRAN website.\nClick “Download R for (Mac) OS X”\nSelect the .pkg link under “Latest Release” that corresponds with your chip type (Apple silicon or Intel).\nFollow the installation instructions. Accept all defaults and install R.\n\n\n\nB.2.2 RStudio\n\nNavigate to the RStudio website.\nDownload the RStudio Desktop installer. It should be something similar to “RStudio-2024.04.2-764.dmg”.\nFollow the installation instructions. Accept all defaults and install RStudio.\nOpen RStudio. If successful, then R and RStudio are installed.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Software Requirements</span>"
    ]
  }
]